---
title: 1st Workshop on Systems for Agentic AI (SAA â€™25)
---

<style>
.post-content h1 {
  font-size: 35px;
}
</style>

# 1st Workshop on Systems for Agentic AI

<div style="text-align: center; margin-bottom: 40px;">
<p style="margin: 7px;"><strong>Date: </strong>October 13, 2025</p>
<p style="margin: 7px;"><strong>Venue: </strong>Seoul, Korea</p>
<p style="margin: 7px;"><strong>Duration: </strong>Half day</p>
<p style="margin: 7px;"><em>In conjunction with the<br/><a href="https://sigops.org/s/conferences/sosp/2025/">31st ACM Symposium on Operating Systems Principles (SOSP '25)</a></em></p>
</div>

As generative and agentic AI systems grow more powerful and widely adopted, the need for efficient, scalable infrastructure to support their deployment has become more pressing than ever. This workshop aims to bring together leading researchers and practitioners from both academia and industry to share insights, challenges, and breakthroughs in building high-performance systems for generative and agentic AI. By fostering collaboration between system designers, infrastructure engineers, and AI researchers, we seek to advance the state of the art in deploying AI systems that are cost-effective, responsive, and capable of interacting with complex real-world environments.

## Call for Presentations

We invite authors to submit an abstract outlining their proposed presentation. We welcome new challenges, system designs, optimization techniques, or lessons learned from production deployments of generative or agentic AI.

### Topics of Interests

- Foundations of Generative and Agentic AI Inference
- Architectural Patterns and Design Considerations for AI Systems
- Cost- and Latency-Optimized Inference Techniques
- System Architectures for Serving AI Agents
- Case Studies from Real-World Deployments
- Bottleneck Identification and Performance Tuning in Model Serving
- Model Compression (Quantization, Pruning, Distillation)
- Caching, Batching, and Speculative Decoding for Throughput Optimization
- Hardware-Aware and System-Level Optimizations (e.g., FlashAttention, Scheduler Tuning)
- Efficient Inference on Specialized Hardware (GPUs, TPUs, Neuron, Custom ASICs)
- Deployment Strategies for Large-Scale Agentic Systems
- Evaluation Methodologies for Inference Optimization
- Scaling Laws and Trends in Inference Workloads

### Important dates

- Abstract submission deadline: August 7, 2025
- Acceptance notification: August 23, 2025
- Workshop date: October 13, 2025

### Presentation abstract submission portal

<em>To be announced</em>

### Program schedule

<em>To be announced</em>

### Organizers

- Gyeong-In Yu, FriendliAI
- Jae Wook Lee, Seoul National University
- Byung-Gon Chun, FriendliAI and Seoul National University

### Sponsorship Opportunities

We welcome sponsors interested in promoting their AI infrastructure tools, model inference services, AI agent services, or cloud platforms.
